  480  lt
  481  t runStreamlitCommand.txt 
  482  rm nohup.out 
  483  nohup streamlit run /home/$(echo $USER)/work/ArticleSummarizer/python/streamlitSummarizer.py --server.port 8501 &
  484  cd ../../MLnotebooks/OCRapp/python/
  485  t runStreamlitCommand.txt 
  486  rm nohup.out 
  487  LocalImageLocation=/home/$(echo $USER)/work/MLnotebooks/OCRapp/images/StudiesAtSmallestScaleNobelPrizes.jpg nohup streamlit run /home/$(echo $USER)/work/MLnotebooks/OCRapp/python/streamlitScan2text.py --server.port 8502 &
  488  cd ../../../document-classification-test/
  489  git status
  490  git pull
  491  git status
  492  git diff notebook/DocumentClassificationTest.ipynb
  493  git status
  494  cd ~/work/
  495  rjupyter 10000 &
  496  git status
  497  git status
  498  cd document-classification-test/
  499  git status
  500  git pull
  501  cd work
  502  rjupyter 10000 &
  503  cd ArticleSummarizer/python/
  504  t runStreamlitCommand.txt 
  505  nohup streamlit run /home/$(echo $USER)/work/ArticleSummarizer/python/streamlitSummarizer.py --server.port 8501 &
  506  cd ../../MLnotebooks/OCRapp/python/
  507  t runStreamlitCommand.txt
  508  LocalImageLocation=/home/$(echo $USER)/work/MLnotebooks/OCRapp/images/StudiesAtSmallestScaleNobelPrizes.jpg nohup streamlit run /home/$(echo $USER)/work/MLnotebooks/OCRapp/python/streamlitScan2text.py --server.port 8502 &
  509  cd ../../../document-classification-test/deployedApp/
  510  ls
  511  t ../test/sampleCurlStrings.txt 
  512  git status
  513  git pull
  514  git status
  515  git add ../python/utility/__init__.py ../python/utility/GridSearchSearchObjEx.pkl ../python/plotHelpers/__init__.py
  516  touch ../python/__init__.py
  517  jupyter notebook list
  518  git status
  519  git pull
  520  git status
  521  git add ../python/__init__.py
  522  git status
  523  ~
  524  git status
  525  git add ../notebook/DocumentClassificationTest.ipynb
  526  rm payload.json 
  527  git status
  528  git rm payload.json zappa_settings.json
  529  git status
  530  git commit -m 'Getting parts of Mlib moved here to work; removing not-used zappa stuff; latest DocumentClassificationTest.ipynb.'
  531  git push
  532  docker build -t blackknightApp:0.2 .
  533  docker build -t blackknightapp:0.2 .
  534  apt install python3-pip
  535  sudo apt auroremove
  536  sudo apt autoremove
  537  git pull
  538  docker build -t blackknightapp:0.2 .
  539  t Dockerfile 
  540  docker build -t blackknightapp:0.2 .
  541  docker build --no-cache -t blackknightapp:0.2 .
  542  git pull
  543  docker build --no-cache -t blackknightapp:0.2 .
  544  git pull
  545  docker build --no-cache -t blackknightapp:0.2 .
  546  emacs -nw Dockerfile 
  547  docker build --no-cache -t blackknightapp:0.2 .
  548  jobs
  549  emacs -nw Dockerfile 
  550  emacs -nw Dockerfile 
  551  docker build -t blackknightapp:0.2 .
  552  emacs -nw Dockerfile 
  553  docker build -t blackknightapp:0.2 .
  554  emacs -nw Dockerfile 
  555  docker build -t blackknightapp:0.2 .
  556  emacs -nw Dockerfile 
  557  docker build -t blackknightapp:0.2 .
  558  emacs -nw Dockerfile 
  559  docker build -t blackknightapp:0.2 .
  560  docker build --no-cache -t blackknightapp:0.2 .
  561  emacs -nw Dockerfile 
  562  emacs -nw Dockerfile 
  563  docker build --no-cache -t blackknightapp:0.2 .
  564  emacs -nw Dockerfile 
  565  docker build -t blackknightapp:0.2 .
  566  docker build -t blackknightapp:0.2 .
  567  emacs -nw Dockerfile 
  568  docker build -t blackknightapp:0.2 .
  569  dpkg-reconfigure tzdata
  570  emacs -nw Dockerfile 
  571  docker build -t blackknightapp:0.2 .
  572  emacs -nw Dockerfile 
  573  docker build -t blackknightapp:0.2 .
  574  emacs -nw Dockerfile 
  575  docker build -t blackknightapp:0.2 .
  576  git log
  577  git checkout ./Dockerfile
  578  git pull
  579  emacs -nw Dockerfile 
  580  docker build -t blackknightapp:0.2 .
  581  emacs -nw Dockerfile 
  582  docker build -t blackknightapp:0.2 .
  583  h
  584  docker build --no-cache -t blackknightapp:0.2 .
  585  emacs -nw Dockerfile 
  586  docker build --no-cache -t blackknightapp:0.2 .
  587  emacs -nw Dockerfile 
  588  docker build --no-cache -t blackknightapp:0.2 .
  589  %
  590  emacs -nw Dockerfile 
  591  docker build -t blackknightapp:0.2 .
  592  emacs -nw requirements.txt 
  593  docker build -t blackknightapp:0.2 .
  594  lt /tmp/
  595  jobs
  596  %2
  597  jobs
  598  pip3 install logging
  599  %
  600  bg
  601  emacs -nw requirements.txt 
  602  docker build -t blackknightapp:0.2 .
  608  docker tag blackknightapp:0.2 797623583483.dkr.ecr.us-east-1.amazonaws.com/blackknight:blackknightapp
  609  docker images
  622  aws ecr get-login-password
  624  aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 797623583483.dkr.ecr.us-east-1.amazonaws.com
  625  docker images
  626  docker push 797623583483.dkr.ecr.us-east-1.amazonaws.com/blackknight:blackknightapp:0.2`
  627  docker push 797623583483.dkr.ecr.us-east-1.amazonaws.com/blackknight:blackknightapp:0.2
  628  docker push 797623583483.dkr.ecr.us-east-1.amazonaws.com/blackknight:blackknightapp
  629  h | tail -150 > ../test/history.txt
------------------------------------------------------------------------------

------- ------- -- ------------- -- -------
Initial testing of predictory.py on lucifer:
------- ------- -- ------------- -- -------
ðŸ¢£ Test with local model path set to trained models
cd ~/work/document-classification-test/deploy/model
MODEL_PATH=/home/wilber/work/document-classification-test/model python3 predictor.py

ðŸ¢£ From another terminal, try
curl -X GET http://localhost:5000/ping
curl -X POST http://localhost:5000/invocations -H 'Content-Type: application/json' -d '{"model": "NaiveBayes", "words": ["586242498a88 9ccf259ca087 54709b24b45f 6bf9c0cb01b4 3486e5fe0d73 c337a85b8ef9 b2125dcdb706 f1424da4e7d6"]}'
curl -X POST http://localhost:5000/invocations -H 'Content-Type: application/json' -d '{"model": "RandomForest", "words": ["586242498a88 9ccf259ca087 54709b24b45f 6bf9c0cb01b4 3486e5fe0d73 c337a85b8ef9 b2125dcdb706 f1424da4e7d6"]}'

------- ------- -- ------ --------- -- -----
Initial testing of docker container on rusty:
------- ------- -- ------ --------- -- -----

ðŸ¢£ As regular user on rusty:
cd ~/work/document-classification-test/deploy
git pull
./build_and_push.sh <blackknightapp3>
â€¢ Look for printout like to get the docker image ID that is built:
  Successfully built <image_hash>

mkdir -p ~/work/document-classification-test/deploy/docker_test/test_dir/model/
scp ../models/*.pkl ~/work/document-classification-test/deploy2/docker_test/test_dir/model/

As root on rusty:
cd /home/mark/work/document-classification-test/deploy/docker_test

â€¢ Run the new docker container (The last hash before the 'serve' is the image
  ID for newly created image.)
docker run -v $(pwd)/test_dir:/home/mark/work/document-classification-test/model  -p 8080:8080 --rm <image_hash> serve

As regular user on rusty again, test new container with
curl -X GET http://localhost:8080/ping
curl -X POST http://localhost:8080/invocations -H 'Content-Type: application/json' -d '{"model": "NaiveBayes", "words": ["586242498a88 9ccf259ca087 54709b24b45f 6bf9c0cb01b4 3486e5fe0d73 c337a85b8ef9 b2125dcdb706 f1424da4e7d6"]}'
curl -X POST http://localhost:8080/invocations -H 'Content-Type: application/json' -d '{"model": "RandomForest", "words": ["586242498a88 9ccf259ca087 54709b24b45f 6bf9c0cb01b4 3486e5fe0d73 c337a85b8ef9 b2125dcdb706 f1424da4e7d6"]}'

------------------------------------------------------------------------------

If all good, verify on AWS that container was pushed to Elastic Container Repository, and if there start building model and end point.

key: MODEL_PATH	value: /opt/ml/model
Version 0.2h:
After push: blackknightapp2h:
  latest: digest: sha256:90dae77473d23bebe4aba53cf3ae360e6fbfbb70d40d3aeea15b0f13791bd933 size: 2410
Repository:
  797623583483.dkr.ecr.us-east-1.amazonaws.com/blackknightapp2h:latest
Model name: blackknight-classifier02h-model
IAM role: arn:aws:iam::797623583483:role/service-role/AmazonSageMaker-ExecutionRole-20210114T135781
Model data location: s3://blackknight/classifierModels.tar.gz
Container Image: 797623583483.dkr.ecr.us-east-1.amazonaws.com/blackknight:blackknightapp2h
Endpoint configuration: blackknight-classifier02h-endpoint-config
Endpoint: blackknight-classifier02h-endpoint
Lambda: blackknight-classifier02h-lambda
Trigger: blackknight-classifier02h-lambda-API


------------------------------------------------------------------------------

key: MODEL_PATH	value: /opt/ml/model
Version 3:
After build, image is: 46ecbf1b6d45
After push: blackknightapp3:
  latest: digest: sha256:ca20ccac873fdb9f805232c769978a245d47358d0cc0abd8f28bca9096e4ec23 size: 2410
Repository:
  797623583483.dkr.ecr.us-east-1.amazonaws.com/blackknightapp3:latest
Model name: blackknight-classifier03-model
**** **** IAM role: arn:aws:iam::797623583483:role/service-role/AmazonSageMaker-ExecutionRole-20210114T135781
Model data location: s3://blackknight/classifierModelsv2.tar.gz
Container Image: 797623583483.dkr.ecr.us-east-1.amazonaws.com/blackknight:blackknightapp3
Endpoint configuration: blackknight-classifier02h-endpoint-config
Endpoint: blackknight-classifier03-endpoint
Lambda: blackknight-classifier03-lambda
Trigger: blackknight-classifier03-lambda-API

------------------------------------------------------------------------------


IAM Policy addition:
-------------------
Select 'Add inline policy' --> JSON tab. Add this JSON:
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "Stmt1464440182000",
            "Effect": "Allow",
            "Action": [
                "sagemaker:InvokeEndpoint"
            ],
            "Resource": [
                "*"
            ]
        }
    ]
}


lambda_function:
---------------
import json
import boto3
import os

ENDPOINT_NAME = os.environ['EndPoint']
runtime = boto3.client('runtime.sagemaker')

def lambda_handler(event, context):
    print("Received event: " + json.dumps(event, indent=2))

    data = json.loads(json.dumps(event))
    print(f'Input {str(data)}')
    payload = json.dumps(data)

    response = runtime.invoke_endpoint(EndpointName=ENDPOINT_NAME,
                                       ContentType='application/json',
				       Body=payload)
    print('Endpoint invoked.')
    result = json.loads(response['Body'].read().decode())
    final = json.dumps(result, indent=2)
    print(f'Output {str(final)}')

    return final


Test --> (A truncated BILL instance)
Request Body:
{"model": "NaiveBayes", "words": ["586242498a88 9ccf259ca087 54709b24b45f 6bf9c0cb01b4 3486e5fe0d73 c337a85b8ef9 b2125dcdb706 f1424da4e7d6 5defc9f531f0 7ec02e30a5b3 f9e92c0357ef 6753b57205cb 5488cb2c0749 1ec85e7e2142 2685f0879380 b2125dcdb706 f1424da4e7d6 5defc9f531f0 b834a58b85b9 036087ac04f9 2bcce4e05d9d 6ca2dd348663 d38820625542 c9a53ea6e219 6dae7d5c1d03 1aba273fa8e4 0d66aace12f3 b6670dfb5ae7 5be138559904 b2125dcdb706 f1424da4e7d6 5defc9f531f0 b834a58b85b9 036087ac04f9 b136f6349cf3 186c2a8b23eb 7772cb33d419 e943e5e5b779 7a5e719bafba cbfb3eb99bea d38820625542 9287e6d15453 c85a9f2e0024 1c303d15eb65 351248ac109a 5ee06767bc0f ed1e3242ee34 cc27fc4409a9 4ce4bfb42e22 63e05aeec02b b9699ce57810 641356219cbc b2125dcdb706 f1424da4e7d6 5defc9f531f0 831d93352e04 21e314d3afcc ebbd827fe2a0 641356219cbc 422068f04236 d19b1c129f40 b9699ce57810 b834a58b85b9 f0666bdbc8a5 036087ac04f9 eeb86a6a04e4 2bcce4e05d9d 48d657cd9861 b643c02ad43a 831d93352e04 21e314d3afcc 2e182c67811b"]}


Streamlit t2.micro instance Public IPv4 DNS:
ec2-54-226-227-175.compute-1.amazonaws.com
